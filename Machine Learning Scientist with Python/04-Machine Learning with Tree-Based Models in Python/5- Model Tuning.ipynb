{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters of a machine learning model are parameters that are not learned from data. They should be set prior to fitting the model to the training set. In this chapter, you'll learn how to tune the hyperparameters of a tree-based model using grid search cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Tuning a CART's Hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Tree hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In the following exercises you&apos;ll revisit the <a href=\"https://www.kaggle.com/uciml/indian-liver-patient-records\">Indian Liver Patient</a> dataset which was introduced in a previous chapter. </p>\n",
    "<p>Your task is to tune the hyperparameters of a classification tree. Given that this dataset is imbalanced, you&apos;ll be using the ROC AUC score as a metric instead of accuracy.</p>\n",
    "<p>We have instantiated a <code>DecisionTreeClassifier</code> and assigned to <code>dt</code> with <code>sklearn</code>&apos;s default hyperparameters. You can inspect the hyperparameters of <code>dt</code> in your console.</p>\n",
    "<p>Which of the following is not a hyperparameter of <code>dt</code>?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First I will import data and do some preprocessing\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "liver=pd.read_csv('datasets/indian_liver_patient/indian_liver_patient.csv')\n",
    "\n",
    "liver=liver.dropna()\n",
    "\n",
    "#More preprocessing \n",
    "#Creating dummy variables, for Gender colum\n",
    "\n",
    "# Create dummy variables: \n",
    "liver = pd.get_dummies(liver)\n",
    "\n",
    "\n",
    "# Create dummy variables with drop_first=True: liver\n",
    "liver_preprocessed = pd.get_dummies(liver, drop_first=True)\n",
    "\n",
    "\n",
    "liver_preprocessed=liver_preprocessed.drop('Gender_Female', axis=1)\n",
    "\n",
    "#note Dataset column is Liver_disease column\n",
    "X=liver_preprocessed.drop('Dataset', axis=1)\n",
    "y=liver_preprocessed['Dataset']\n",
    "\n",
    "#Import train_test_split from sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED=1\n",
    "\n",
    "# Split the data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,\n",
    "                                                    random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'presort': False,\n",
       " 'random_state': None,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Set the tree's hyperparameter grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In this exercise, you&apos;ll manually set the grid of hyperparameters that will be used to tune the classification tree <code>dt</code> and find the optimal classifier in the next exercise.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><p>Define a grid of hyperparameters corresponding to a Python dictionary called <code>params_dt</code> with:</p>\n",
    "<ul>\n",
    "<li><p>the key <code>&apos;max_depth&apos;</code> set to a list of values 2, 3, and 4</p></li>\n",
    "<li><p>the key <code>&apos;min_samples_leaf&apos;</code> set to a list of values 0.12, 0.14, 0.16, 0.18</p></li></ul></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define params_dt\n",
    "params_dt = {'max_depth': [2,3,4],\n",
    "             'min_samples_leaf': [0.12, 0.14, 0.16, 0.18]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4- Search for the optimal tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In this exercise, you&apos;ll perform grid search using 5-fold cross validation to find <code>dt</code>&apos;s optimal hyperparameters. Note that because grid search is an exhaustive process, it may take a lot time to train the model. Here you&apos;ll only be instantiating the <code>GridSearchCV</code> object without fitting it to the training set. As discussed in the video, you can train such an object similar to any scikit-learn estimator by using the <code>.fit()</code> method:</p>\n",
    "<pre><code>grid_object.fit(X_train, y_train)\n",
    "</code></pre>\n",
    "<p>An untuned classification tree <code>dt</code> as well as the dictionary <code>params_dt</code> that you defined in the previous exercise are available in your workspace.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><p>Import <code>GridSearchCV</code> from <code>sklearn.model_selection</code>.</p></li>\n",
    "<li><p>Instantiate a <code>GridSearchCV</code> object using 5-fold CV by setting the parameters:</p>\n",
    "<ul>\n",
    "<li><p><code>estimator</code> to <code>dt</code>, <code>param_grid</code> to <code>params_dt</code> and</p></li>\n",
    "<li><p><code>scoring</code> to <code>&apos;roc_auc&apos;</code>.</p></li></ul></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Instantiate grid_dt\n",
    "grid_dt = GridSearchCV(estimator=dt,\n",
    "                       param_grid=params_dt,\n",
    "                       scoring='roc_auc',\n",
    "                       cv=5,\n",
    "                       n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5- Evaluate the optimal tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In this exercise, you&apos;ll evaluate the test set ROC AUC score of <code>grid_dt</code>&apos;s optimal model. </p>\n",
    "<p>The dataset is already loaded and processed for you (numerical features are standardized); it is split into 80% train and 20% test. <code>X_test</code>, <code>y_test</code> are available in your workspace. In addition, we have also loaded the trained <code>GridSearchCV</code> object <code>grid_dt</code> that you instantiated in the previous exercise. Note that <code>grid_dt</code> was trained as follows:</p>\n",
    "<pre><code>grid_dt.fit(X_train, y_train)\n",
    "</code></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><p>Import <code>roc_auc_score</code> from <code>sklearn.metrics</code>. </p></li>\n",
    "<li><p>Extract the <code>.best_estimator_</code> attribute from <code>grid_dt</code> and assign it to <code>best_model</code>. </p></li>\n",
    "<li><p>Predict the test set probabilities of obtaining the positive class <code>y_pred_proba</code>. </p></li>\n",
    "<li><p>Compute the test set ROC AUC score <code>test_roc_auc</code> of <code>best_model</code>.</p></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort=False, random_state=None,\n",
       "                                              splitter='best'),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'max_depth': [2, 3, 4],\n",
       "                         'min_samples_leaf': [0.12, 0.14, 0.16, 0.18]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit 'grid_dt' to the training set\n",
    "grid_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set ROC AUC score: 0.731\n"
     ]
    }
   ],
   "source": [
    "# Import roc_auc_score from sklearn.metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# Extract the best estimator\n",
    "best_model = grid_dt.best_estimator_\n",
    "\n",
    "# Predict the test set probabilities of the positive class\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Compute test_roc_auc\n",
    "test_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Print test_roc_auc\n",
    "print('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Great work! An untuned classification-tree would achieve a ROC AUC score of 0.54!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7172924694361786"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract best CV score from 'grid_dt'\n",
    "best_CV_score = grid_dt.best_score_\n",
    "print('Best CV accuracy'.format(best_CV_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyerparameters:\n",
      " {'max_depth': 3, 'min_samples_leaf': 0.12}\n"
     ]
    }
   ],
   "source": [
    "# Extract best hyperparameters from 'grid_dt'\n",
    "best_hyperparams = grid_dt.best_params_\n",
    "print('Best hyerparameters:\\n', best_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6- Tuning a RF's Hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7- Random forests hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In the following exercises, you&apos;ll be revisiting the <a href=\"https://www.kaggle.com/c/bike-sharing-demand\">Bike Sharing Demand</a> dataset that was introduced in a previous chapter. Recall that your task is to predict the bike rental demand using historical weather data from the Capital Bikeshare program in Washington, D.C.. For this purpose, you&apos;ll be tuning the hyperparameters of a Random Forests regressor.</p>\n",
    "<p>We have instantiated a <code>RandomForestRegressor</code> called <code>rf</code> using <code>sklearn</code>&apos;s default hyperparameters. You can inspect the hyperparameters of <code>rf</code> in your console.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data and preprocessing \n",
    "\n",
    "bikes=pd.read_csv('datasets/bikes.csv')\n",
    "\n",
    "\n",
    "X=bikes.drop('cnt', axis=1)\n",
    "y=bikes['cnt']\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.20,\n",
    "                                                 random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf=RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'criterion': 'mse',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 'warn',\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8- Set the hyperparameter grid of RF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In this exercise, you&apos;ll manually set the grid of hyperparameters that will be used to tune <code>rf</code>&apos;s hyperparameters and find the optimal regressor. For this purpose, you will be constructing a grid of hyperparameters and tune the number of estimators, the maximum number of features used when splitting each node and the minimum number of samples (or fraction) per leaf.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><p>Define a grid of hyperparameters corresponding to a Python dictionary called <code>params_rf</code> with:</p>\n",
    "<ul>\n",
    "<li><p>the key <code>&apos;n_estimators&apos;</code> set to a list of values 100, 350, 500</p></li>\n",
    "<li><p>the key <code>&apos;max_features&apos;</code> set to a list of values &apos;log2&apos;, &apos;auto&apos;, &apos;sqrt&apos;</p></li>\n",
    "<li><p>the key <code>&apos;min_samples_leaf&apos;</code> set to a list of values 2, 10, 30</p></li></ul></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dictionary 'params_rf'\n",
    "params_rf = {'n_estimators': [100, 350, 500],\n",
    "    'max_features': ['log2', 'auto', 'sqrt'],\n",
    "    'min_samples_leaf': [2,10,30]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9- Search for the optimal forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In this exercise, you&apos;ll perform grid search using 3-fold cross validation to find <code>rf</code>&apos;s optimal hyperparameters. To evaluate each model in the grid, you&apos;ll be using the <a href=\"http://scikit-learn.org/stable/modules/model_evaluation.html\">negative mean squared error</a> metric. </p>\n",
    "<p>Note that because grid search is an exhaustive search process, it may take a lot time to train the model. Here you&apos;ll only be instantiating the <code>GridSearchCV</code> object without fitting it to the training set. As discussed in the video, you can train such an object similar to any scikit-learn estimator by using the <code>.fit()</code> method: </p>\n",
    "<pre><code>grid_object.fit(X_train, y_train)\n",
    "</code></pre>\n",
    "<p>The untuned random forests regressor model <code>rf</code> as well as the dictionary <code>params_rf</code> that you defined in the  previous exercise are available in your workspace.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><p>Import <code>GridSearchCV</code> from <code>sklearn.model_selection</code>.</p></li>\n",
    "<li><p>Instantiate a <code>GridSearchCV</code> object using 3-fold CV by using negative mean squared error as the scoring metric.</p></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Instantiate grid_rf\n",
    "grid_rf = GridSearchCV(estimator=rf,\n",
    "                       param_grid=params_rf,\n",
    "                       scoring=\"neg_mean_squared_error\",\n",
    "                       cv=3,\n",
    "                       verbose=1,\n",
    "                       n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed:   23.3s finished\n",
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=RandomForestRegressor(bootstrap=True, criterion='mse',\n",
       "                                             max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators='warn', n_jobs=None,\n",
       "                                             oob_score=False, random_state=None,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'max_features': ['log2', 'auto', 'sqrt'],\n",
       "                         'min_samples_leaf': [2, 10, 30],\n",
       "                         'n_estimators': [100, 350, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10-Evaluate the optimal forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In this last exercise of the course, you&apos;ll evaluate the test set RMSE of <code>grid_rf</code>&apos;s optimal model.</p>\n",
    "<p>The dataset is already loaded and processed for you and is split into 80% train and 20% test. In your environment are available <code>X_test</code>, <code>y_test</code> and the function <code>mean_squared_error</code> from <code>sklearn.metrics</code> under the alias <code>MSE</code>.  In addition, we have also loaded the trained <code>GridSearchCV</code> object <code>grid_rf</code> that you instantiated in the previous exercise. Note that <code>grid_rf</code> was trained as follows:</p>\n",
    "<pre><code>grid_rf.fit(X_train, y_train)\n",
    "</code></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><p>Import <code>mean_squared_error</code> as <code>MSE</code> from <code>sklearn.metrics</code>. </p></li>\n",
    "<li><p>Extract the best estimator from <code>grid_rf</code> and assign it to <code>best_model</code>. </p></li>\n",
    "<li><p>Predict <code>best_model</code>&apos;s test set labels and assign the result to <code>y_pred</code>.</p></li>\n",
    "<li><p>Compute <code>best_model</code>&apos;s test set RMSE.</p></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE of best model: 51.411\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error from sklearn.metrics as MSE \n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Extract the best estimator\n",
    "best_model = grid_rf.best_estimator_\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Compute rmse_test\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test RMSE of best model: {:.3f}'.format(rmse_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
