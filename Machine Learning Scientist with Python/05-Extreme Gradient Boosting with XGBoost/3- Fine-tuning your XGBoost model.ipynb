{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter will teach you how to make your XGBoost models as performant as possible. You'll learn about the variety of parameters that can be adjusted to alter the behavior of XGBoost and how to tune them efficiently so that you can supercharge the performance of your models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Why tune your model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- When is tuning your model a bad idea?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now that you&apos;ve seen the effect that tuning has on the overall performance of your XGBoost model, let&apos;s turn the question on its head and see if you can figure out when tuning your model might not be the best idea. <strong>Given that model tuning can be time-intensive and complicated, which of the following scenarios would NOT call for careful tuning of your model</strong>?</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- You have lots of examples from some dataset and very many features at your disposal.\n",
    "\n",
    "- You are very short on time before you must push an initial model to production and have little data to train your model on. (answer)\n",
    "\n",
    "- You have access to a multi-core (64 cores) server with lots of memory (200GB RAM) and no time constraints.\n",
    "\n",
    "- You must squeeze out every last bit of performance out of your xgboost model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Tuning the number of boosting rounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Let&apos;s start with parameter tuning by seeing how the number of boosting rounds (number of trees you build) impacts the out-of-sample performance of your XGBoost model. You&apos;ll use <code>xgb.cv()</code> inside a <code>for</code> loop and build one model per <code>num_boost_round</code> parameter.</p>\n",
    "<p>Here, you&apos;ll continue working with the Ames housing dataset. The features are available in the array <code>X</code>, and the target vector is contained in <code>y</code>.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Create a <code>DMatrix</code> called <code>housing_dmatrix</code> from <code>X</code> and <code>y</code>.</li>\n",
    "<li>Create a parameter dictionary called <code>params</code>, passing in the appropriate <code>&quot;objective&quot;</code> (<code>&quot;reg:linear&quot;</code>) and <code>&quot;max_depth&quot;</code> (set it to <code>3</code>).</li>\n",
    "<li>Iterate over <code>num_rounds</code> inside a <code>for</code> loop and perform 3-fold cross-validation. In each iteration of the loop, pass in the current number of boosting rounds (<code>curr_num_rounds</code>) to <code>xgb.cv()</code> as the argument to <code>num_boost_round</code>. </li>\n",
    "<li>Append the final boosting round RMSE for each cross-validated XGBoost model to the <code>final_rmse_per_round</code> list.</li>\n",
    "<li><code>num_rounds</code> and <code>final_rmse_per_round</code> have been zipped and converted into a DataFrame so you can easily see how the model performs with each boosting round. Hit &apos;Submit Answer&apos; to see the results!</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "housing_data = pd.read_csv(\"datasets/ames_housing_trimmed_processed.csv\")\n",
    "X=housing_data.drop('SalePrice', axis=1)\n",
    "y=housing_data['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:08:50] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:08:50] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:08:50] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:08:51] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:08:51] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:08:51] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:08:51] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:08:51] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:08:51] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "   num_boosting_rounds          rmse\n",
      "0                    5  50903.300781\n",
      "1                   10  34774.192708\n",
      "2                   15  32895.097005\n"
     ]
    }
   ],
   "source": [
    " # Create the DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Create the parameter dictionary for each tree: params \n",
    "params = {\"objective\":\"reg:linear\", \"max_depth\":3}\n",
    "\n",
    "# Create list of number of boosting rounds\n",
    "num_rounds = [5, 10, 15]\n",
    "\n",
    "# Empty list to store final round rmse per XGBoost model\n",
    "final_rmse_per_round = []\n",
    "\n",
    "# Iterate over num_rounds and build one model per num_boost_round parameter\n",
    "for curr_num_rounds in num_rounds:\n",
    "\n",
    "    # Perform cross-validation: cv_results\n",
    "    cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=3, num_boost_round=curr_num_rounds, metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "    \n",
    "    # Append final round RMSE\n",
    "    final_rmse_per_round.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\n",
    "\n",
    "# Print the resultant DataFrame\n",
    "num_rounds_rmses = list(zip(num_rounds, final_rmse_per_round))\n",
    "print(pd.DataFrame(num_rounds_rmses,columns=[\"num_boosting_rounds\",\"rmse\"]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Awesome! As you can see, increasing the number of boosting rounds decreases the RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4- Automated boosting round selection using early_stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now, instead of attempting to cherry pick the best possible number of boosting rounds, you can very easily have XGBoost automatically select the number of boosting rounds for you within <code>xgb.cv()</code>. This is done using a technique called <strong>early stopping</strong>. </p>\n",
    "<p><strong>Early stopping</strong> works by testing the XGBoost model after every boosting round against a hold-out dataset and stopping the creation of additional boosting rounds (thereby finishing training of the model early) if the hold-out metric (<code>&quot;rmse&quot;</code> in our case) does not improve for a given number of rounds. Here you will use the <code>early_stopping_rounds</code> parameter in <code>xgb.cv()</code> with a large possible number of boosting rounds (50). Bear in mind that if the holdout metric continuously improves up through when <code>num_boost_rounds</code> is reached, then early stopping does not occur.</p>\n",
    "<p>Here, the <code>DMatrix</code> and parameter dictionary have been created for you. Your task is to use cross-validation with early stopping. Go for it!</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Perform 3-fold cross-validation with early stopping and <code>&quot;rmse&quot;</code> as your metric. Use <code>10</code> early stopping rounds and <code>50</code> boosting rounds. Specify a <code>seed</code> of <code>123</code> and make sure the output is a <code>pandas</code> DataFrame. Remember to specify the other parameters such as <code>dtrain</code>, <code>params</code>, and <code>metrics</code>.</li>\n",
    "<li>Print <code>cv_results</code>.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:15:55] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:15:55] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:15:55] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "    train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
      "0     141871.630208      403.632409   142640.651042     705.571916\n",
      "1     103057.028646       73.769561   104907.666667     111.114933\n",
      "2      75975.963541      253.734987    79262.059895     563.766991\n",
      "3      57420.529948      521.653556    61620.135417    1087.690754\n",
      "4      44552.955729      544.169200    50437.561198    1846.448222\n",
      "5      35763.949219      681.798925    43035.660156    2034.469858\n",
      "6      29861.464844      769.572234    38600.881510    2169.800969\n",
      "7      25994.673828      756.522016    36071.817708    2109.795430\n",
      "8      23306.833984      759.237670    34383.184896    1934.546688\n",
      "9      21459.768880      745.624404    33509.139974    1887.375633\n",
      "10     20148.720703      749.612103    32916.806641    1850.893136\n",
      "11     19215.382813      641.387376    32197.833984    1734.458659\n",
      "12     18627.388021      716.257152    31770.852865    1802.155484\n",
      "13     17960.695963      557.043993    31482.782552    1779.123767\n",
      "14     17559.736979      631.412969    31389.990234    1892.319927\n",
      "15     17205.713541      590.173229    31302.882813    1955.165974\n",
      "16     16876.571940      703.631755    31234.058594    1880.705796\n",
      "17     16597.662435      703.677150    31318.349610    1828.861710\n",
      "18     16330.460612      607.273536    31323.633464    1775.909418\n",
      "19     16005.973307      520.471073    31204.136068    1739.077074\n",
      "20     15814.301432      518.604477    31089.861979    1756.021059\n",
      "21     15493.405924      505.616658    31047.996094    1624.673955\n",
      "22     15270.733724      502.019487    31056.916667    1668.043013\n",
      "23     15086.382487      503.912747    31024.984375    1548.985605\n",
      "24     14917.607422      486.206187    30983.684896    1663.128699\n",
      "25     14709.589193      449.667058    30989.476563    1686.667469\n",
      "26     14457.286458      376.787206    30952.112630    1613.171737\n",
      "27     14185.566406      383.102876    31066.902344    1648.534310\n",
      "28     13934.067383      473.465256    31095.639974    1709.224745\n",
      "29     13749.646159      473.671021    31103.888021    1778.879154\n",
      "30     13549.836914      454.898923    30976.086589    1744.515448\n",
      "31     13413.484375      399.603774    30938.469401    1746.052597\n",
      "32     13275.916016      415.408786    30931.000651    1772.468466\n",
      "33     13085.878581      493.792614    30929.056640    1765.538820\n",
      "34     12947.181641      517.790106    30890.631510    1786.509640\n",
      "35     12846.027669      547.732453    30884.494141    1769.728223\n",
      "36     12702.378255      505.524001    30833.542318    1691.002985\n",
      "37     12532.244466      508.298083    30856.688802    1771.445459\n",
      "38     12384.054362      536.225108    30818.016927    1782.784718\n",
      "39     12198.443685      545.165136    30839.392578    1847.326928\n",
      "40     12054.583333      508.841412    30776.964844    1912.781000\n",
      "41     11897.037109      477.177991    30794.701172    1919.675316\n",
      "42     11756.221680      502.992419    30780.954427    1906.819550\n",
      "43     11618.846029      519.838297    30783.755208    1951.260237\n",
      "44     11484.080078      578.428571    30776.730469    1953.445852\n",
      "45     11356.552734      565.368794    30758.543620    1947.456345\n",
      "46     11193.556966      552.298481    30729.972005    1985.699316\n",
      "47     11071.315104      604.089611    30732.664062    1966.998275\n",
      "48     10950.778646      574.862348    30712.240885    1957.751118\n",
      "49     10824.865560      576.666458    30720.854818    1950.511520\n"
     ]
    }
   ],
   "source": [
    "# Create your housing DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Create the parameter dictionary for each tree: params\n",
    "params = {\"objective\":\"reg:linear\", \"max_depth\":4}\n",
    "\n",
    "# Perform cross-validation with early stopping: cv_results\n",
    "cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=3, num_boost_round=50, early_stopping_rounds=10, metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "\n",
    "# Print cv_results\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5- Overview of XGBoost's hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6- Tuning eta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>It&apos;s time to practice tuning other XGBoost hyperparameters in earnest and observing their effect on model performance! You&apos;ll begin by tuning the <code>&quot;eta&quot;</code>, also known as the learning rate.</p>\n",
    "<p>The learning rate in XGBoost is a parameter that can range between <code>0</code> and <code>1</code>, with higher values of <code>&quot;eta&quot;</code> penalizing feature weights more strongly, causing much stronger regularization.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Create a list called <code>eta_vals</code> to store the following <code>&quot;eta&quot;</code> values: <code>0.001</code>, <code>0.01</code>, and <code>0.1</code>.</li>\n",
    "<li>Iterate over your <code>eta_vals</code> list using a <code>for</code> loop.</li>\n",
    "<li>In each iteration of the <code>for</code> loop, set the <code>&quot;eta&quot;</code> key of <code>params</code> to be equal to <code>curr_val</code>. Then, perform 3-fold cross-validation with early stopping (<code>5</code> rounds), <code>10</code> boosting rounds, a metric of <code>&quot;rmse&quot;</code>, and a <code>seed</code> of <code>123</code>. Ensure the output is a DataFrame.</li>\n",
    "<li>Append the final round RMSE to the <code>best_rmse</code> list.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:30:57] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:30:57] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:30:57] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:30:57] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:30:57] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:30:57] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:30:57] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:30:57] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:30:57] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "     eta      best_rmse\n",
      "0  0.001  195736.406250\n",
      "1  0.010  179932.177083\n",
      "2  0.100   79759.414063\n"
     ]
    }
   ],
   "source": [
    "# Create your housing DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Create the parameter dictionary for each tree (boosting round)\n",
    "params = {\"objective\":\"reg:linear\", \"max_depth\":3}\n",
    "\n",
    "# Create list of eta values and empty list to store final round rmse per xgboost model\n",
    "eta_vals = [0.001, 0.01, 0.1]\n",
    "best_rmse = []\n",
    "\n",
    "# Systematically vary the eta \n",
    "for curr_val in eta_vals:\n",
    "\n",
    "    params[\"eta\"] = curr_val\n",
    "    \n",
    "    # Perform cross-validation: cv_results\n",
    "    cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=3, early_stopping_rounds=5, num_boost_round=10, metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Append the final round rmse to best_rmse\n",
    "    best_rmse.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\n",
    "\n",
    "# Print the resultant DataFrame\n",
    "print(pd.DataFrame(list(zip(eta_vals, best_rmse)), columns=[\"eta\",\"best_rmse\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7- Tuning max_depth\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In this exercise, your job is to tune <code>max_depth</code>, which is the parameter that dictates the maximum depth that each tree in a boosting round can grow to. Smaller values will lead to shallower trees, and larger values to deeper trees.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Create a list called <code>max_depths</code> to store the following <code>&quot;max_depth&quot;</code> values: <code>2</code>, <code>5</code>, <code>10</code>, and <code>20</code>.</li>\n",
    "<li>Iterate over your <code>max_depths</code> list using a <code>for</code> loop.</li>\n",
    "<li>Systematically vary <code>&quot;max_depth&quot;</code> in each iteration of the <code>for</code> loop and perform 2-fold cross-validation with early stopping (<code>5</code> rounds), <code>10</code> boosting rounds, a metric of <code>&quot;rmse&quot;</code>, and a <code>seed</code> of <code>123</code>. Ensure the output is a DataFrame.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:36:39] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:36:39] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:36:39] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:36:39] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:36:39] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:36:39] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:36:39] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:36:39] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "   max_depth     best_rmse\n",
      "0          2  37957.468750\n",
      "1          5  35596.601562\n",
      "2         10  36065.548828\n",
      "3         20  36739.578125\n"
     ]
    }
   ],
   "source": [
    "# Create your housing DMatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "# Create the parameter dictionary\n",
    "params = {\"objective\":\"reg:linear\"}\n",
    "\n",
    "# Create list of max_depth values\n",
    "max_depths = [2,5,10,20]\n",
    "best_rmse = []\n",
    "\n",
    "# Systematically vary the max_depth\n",
    "for curr_val in max_depths:\n",
    "\n",
    "    params[\"max_depth\"] = curr_val\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=2,\n",
    "                        early_stopping_rounds=5, num_boost_round=10,\n",
    "                        metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Append the final round rmse to best_rmse\n",
    "    best_rmse.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\n",
    "\n",
    "# Print the resultant DataFrame\n",
    "print(pd.DataFrame(list(zip(max_depths, best_rmse)),columns=[\"max_depth\",\"best_rmse\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8- Tuning colsample_bytree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now, it&apos;s time to tune <code>&quot;colsample_bytree&quot;</code>. You&apos;ve already seen this if you&apos;ve ever worked with scikit-learn&apos;s <code>RandomForestClassifier</code> or <code>RandomForestRegressor</code>, where it just was called <code>max_features</code>. In both <code>xgboost</code> and <code>sklearn</code>, this parameter (although named differently) simply specifies the fraction of features to choose from at every split in a given tree. In <code>xgboost</code>, <code>colsample_bytree</code> must be specified as a float between 0 and 1.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Create a list called <code>colsample_bytree_vals</code> to store the values <code>0.1</code>, <code>0.5</code>, <code>0.8</code>, and <code>1</code>.</li>\n",
    "<li>Systematically vary <code>&quot;colsample_bytree&quot;</code> and perform cross-validation, exactly as you did with <code>max_depth</code> and <code>eta</code> previously.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:39:15] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:39:15] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:39:15] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:39:15] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:39:15] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:39:15] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:39:15] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:39:15] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "   colsample_bytree     best_rmse\n",
      "0               0.1  48193.453125\n",
      "1               0.5  36013.541015\n",
      "2               0.8  35932.962891\n",
      "3               1.0  35836.042969\n"
     ]
    }
   ],
   "source": [
    "# Create your housing DMatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "# Create the parameter dictionary\n",
    "params={\"objective\":\"reg:linear\",\"max_depth\":3}\n",
    "\n",
    "# Create list of hyperparameter values: colsample_bytree_vals\n",
    "colsample_bytree_vals = [0.1, 0.5, 0.8, 1]\n",
    "best_rmse = []\n",
    "\n",
    "# Systematically vary the hyperparameter value \n",
    "for curr_val in colsample_bytree_vals:\n",
    "\n",
    "    params['colsample_bytree'] = curr_val\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=2,\n",
    "                 num_boost_round=10, early_stopping_rounds=5,\n",
    "                 metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "    \n",
    "    # Append the final round rmse to best_rmse\n",
    "    best_rmse.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\n",
    "\n",
    "# Print the resultant DataFrame\n",
    "print(pd.DataFrame(list(zip(colsample_bytree_vals, best_rmse)), \n",
    "                   columns=[\"colsample_bytree\",\"best_rmse\"]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Awesome! There are several other individual parameters that you can tune, such as \"subsample\", which dictates the fraction of the training data that is used during any given boosting round. Next up: Grid Search and Random Search to tune XGBoost hyperparameters more efficiently!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9- Review of grid search and random search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10- Grid search with XGBoost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now that you&apos;ve learned how to tune parameters individually with XGBoost, let&apos;s take your parameter tuning to the next level by using scikit-learn&apos;s <code>GridSearch</code> and <code>RandomizedSearch</code> capabilities with internal cross-validation using the <code>GridSearchCV</code> and <code>RandomizedSearchCV</code> functions. You will use these to find the best model exhaustively from a collection of possible parameter values across multiple parameters simultaneously. Let&apos;s get to work, starting with <code>GridSearchCV</code>!</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Create a parameter grid called <code>gbm_param_grid</code> that contains a list of <code>&quot;colsample_bytree&quot;</code> values (<code>0.3</code>, <code>0.7</code>), a list with a single value for <code>&quot;n_estimators&quot;</code> (<code>50</code>), and a list of 2 <code>&quot;max_depth&quot;</code> (<code>2</code>, <code>5</code>) values.</li>\n",
    "<li>Instantiate an <code>XGBRegressor</code> object called <code>gbm</code>.</li>\n",
    "<li>Create a <code>GridSearchCV</code> object called <code>grid_mse</code>, passing in: the parameter grid to <code>param_grid</code>, the <code>XGBRegressor</code> to <code>estimator</code>, <code>&quot;neg_mean_squared_error&quot;</code> to <code>scoring</code>, and <code>4</code> to <code>cv</code>. Also specify <code>verbose=1</code> so you can better understand the output.</li>\n",
    "<li>Fit the <code>GridSearchCV</code> object to <code>X</code> and <code>y</code>.</li>\n",
    "<li>Print the best parameter values and lowest RMSE, using the <code>.best_params_</code> and <code>.best_score_</code> attributes, respectively, of <code>grid_mse</code>.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:13:04] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:13:05] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:13:05] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:13:05] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:13:05] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:13:05] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:13:05] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:13:05] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:13:05] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:13:06] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:13:06] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:13:06] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:13:06] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:13:06] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:13:06] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:13:06] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    2.2s finished\n",
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:13:07] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Best parameters found:  {'colsample_bytree': 0.7, 'max_depth': 5, 'n_estimators': 50}\n",
      "Lowest RMSE found:  29916.562522854438\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the parameter grid: gbm_param_grid\n",
    "gbm_param_grid = {\n",
    "    'colsample_bytree': [0.3, 0.7],\n",
    "    'n_estimators': [50],\n",
    "    'max_depth': [2, 5]\n",
    "}\n",
    "\n",
    "# Instantiate the regressor: gbm\n",
    "gbm = xgb.XGBRegressor()\n",
    "\n",
    "# Perform grid search: grid_mse\n",
    "grid_mse = GridSearchCV(param_grid=gbm_param_grid, estimator=gbm, scoring=\"neg_mean_squared_error\", cv=4, verbose=1)\n",
    "\n",
    "\n",
    "# Fit grid_mse to the data\n",
    "grid_mse.fit(X,y)\n",
    "\n",
    "# Print the best parameters and lowest RMSE\n",
    "print(\"Best parameters found: \", grid_mse.best_params_)\n",
    "print(\"Lowest RMSE found: \", np.sqrt(np.abs(grid_mse.best_score_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11- Random search with XGBoost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Often, <code>GridSearchCV</code> can be really time consuming, so in practice, you may want to use <code>RandomizedSearchCV</code> instead, as you will do in this exercise. The good news is you only have to make a few modifications to your <code>GridSearchCV</code> code to do <code>RandomizedSearchCV</code>. The key difference is you have to specify a <code>param_distributions</code> parameter instead of a <code>param_grid</code> parameter.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Create a parameter grid called <code>gbm_param_grid</code> that contains a list with a single value for <code>&apos;n_estimators&apos;</code> (<code>25</code>), and a list of <code>&apos;max_depth&apos;</code> values between <code>2</code> and <code>11</code> for <code>&apos;max_depth&apos;</code> - use <code>range(2, 12)</code> for this. </li>\n",
    "<li>Create a <code>RandomizedSearchCV</code> object called <code>randomized_mse</code>, passing in: the parameter grid to <code>param_distributions</code>, the <code>XGBRegressor</code> to <code>estimator</code>, <code>&quot;neg_mean_squared_error&quot;</code> to <code>scoring</code>, <code>5</code> to <code>n_iter</code>, and <code>4</code> to <code>cv</code>. Also specify <code>verbose=1</code> so you can better understand the output.</li>\n",
    "<li>Fit the <code>RandomizedSearchCV</code> object to <code>X</code> and <code>y</code>.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "[19:19:43] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:19:43] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:19:43] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:19:43] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:19:43] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:19:43] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:19:44] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:19:44] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:19:44] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:19:44] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:19:44] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:19:44] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:19:44] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:19:45] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:19:45] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:19:45] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:19:45] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:19:45] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:19:45] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:19:45] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:19:45] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Best parameters found:  {'n_estimators': 25, 'max_depth': 5}\n",
      "Lowest RMSE found:  36636.35808132903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    2.5s finished\n",
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\MohammedTaysser\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Create the parameter grid: gbm_param_grid \n",
    "gbm_param_grid = {\n",
    "    'n_estimators': [25],\n",
    "    'max_depth': range(2,12)\n",
    "}\n",
    "\n",
    "# Instantiate the regressor: gbm\n",
    "gbm = xgb.XGBRegressor(n_estimators=10)\n",
    "\n",
    "# Perform random search: grid_mse\n",
    "randomized_mse = RandomizedSearchCV(param_distributions=gbm_param_grid,\n",
    "                                    estimator=gbm, scoring=\"neg_mean_squared_error\",\n",
    "                                    n_iter=5, cv=4, verbose=1)\n",
    "\n",
    "\n",
    "# Fit randomized_mse to the data\n",
    "randomized_mse.fit(X,y)\n",
    "\n",
    "# Print the best parameters and lowest RMSE\n",
    "print(\"Best parameters found: \", randomized_mse.best_params_)\n",
    "print(\"Lowest RMSE found: \", np.sqrt(np.abs(randomized_mse.best_score_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12- Limits of grid search and random search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13- When should you use grid search and random search?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've seen some of the drawbacks of grid search and random search, which of the following most accurately describes why both random search and grid search are non-ideal search hyperparameter tuning strategies in all scenarios?\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The search space size can be massive for Grid Search in certain cases, whereas for Random Search the number of hyperparameters has a significant effect on how long it takes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
